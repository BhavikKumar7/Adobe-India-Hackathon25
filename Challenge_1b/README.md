📄 Persona-Driven Document Intelligence (Challenge-1B)

A minimal-footprint Docker container (≤ 1 GB) that extracts and ranks the most relevant sections from a folder of PDFs based on a given persona and job-to-be-done. It's designed for efficiency, processing 3-7 PDFs in under 60 seconds.

🚀 Quick Start# 📄 Persona-Driven Document Intelligence (Challenge-1B)

A minimal-footprint Docker container (≤ 1 GB) that extracts and ranks the most relevant sections from a folder of PDFs based on a given persona and job-to-be-done. It's designed for efficiency, processing 3-7 PDFs in under 60 seconds.

## 🚀 Quick Start

Follow these steps to get the solution running.

### 1. Build the Docker Image (Once)

From the project's root directory, run the following command to build the Docker image:

```bash
docker build -t persona-doc-intel:1b .
```

### 2. Run the Container

Execute the container, mounting your collection folder as a volume. The command below uses Collection 1 as an example.

#### For Windows (PowerShell):

```powershell
docker run --rm `
  -v "${PWD}/Collection 1:/workspace/input:ro" `
  -v "${PWD}/Collection 1:/workspace/output" `
  persona-doc-intel:1b
```

#### For macOS/Linux (Bash):

```bash
docker run --rm \
  -v "$(pwd)/Collection 1:/workspace/input:ro" \
  -v "$(pwd)/Collection 1:/workspace/output" \
  persona-doc-intel:1b
```

To process other collections, simply replace `Collection 1` with `Collection 2` or `Collection 3`. The output `challenge1b_output.json` will be generated inside the respective collection folder.

## 📁 Project Layout

```
Challenge_1b/
├── Dockerfile                 # Multi-stage Docker build file (≤ 1 GB)
├── README.md                  # This documentation file
├── app/
│   ├── main.py                # Main application entry point
│   ├── pdf_parser.py          # Extracts text sections using PyMuPDF
│   ├── ranker.py              # Ranks sections using an ONNX MiniLM model
│   └── requirements.txt       # Runtime dependencies only
├── Collection 1/
│   ├── PDFs/                  # Source PDFs (e.g., travel guides)
│   ├── challenge1b_input.json
│   └── challenge1b_output.json # Generated by the container
├── Collection 2/              # Additional data collection (e.g., Acrobat tutorials)
└── Collection 3/              # Additional data collection (e.g., recipe guides)
```

## 📥 Input / 📤 Output Schema

The container uses JSON files for input and output, following a specific schema.

### Input (`input/challenge1b_input.json`)

```json
{
  "challenge_info": {
    "challenge_id": "round_1b_002",
    "test_case_name": "Travel Planning"
  },
  "documents": [
    {
      "filename": "guide1.pdf",
      "title": "Guide 1"
    }
  ],
  "persona": {
    "role": "Travel Planner"
  },
  "job_to_be_done": {
    "task": "Plan a 4-day trip to South of France for 10 college friends"
  }
}
```

### Output (`output/challenge1b_output.json`)

```json
{
  "metadata": {
    "input_documents": ["guide1.pdf"],
    "persona": "Travel Planner",
    "job_to_be_done": "Plan a 4-day trip to South of France for 10 college friends"
  },
  "extracted_sections": [
    {
      "document": "guide1.pdf",
      "section_title": "4-Day Itinerary",
      "importance_rank": 1,
      "page_number": 5
    }
  ],
  "subsection_analysis": [
    {
      "document": "guide1.pdf",
      "refined_text": "Day 1: Arrive Nice – Old Town stroll…",
      "page_number": 5
    }
  ]
}
```

## 🔧 Tech Stack (Runtime)

The solution relies on a lightweight stack to meet the size and performance constraints.

| Component | Approx. Size | Purpose |
|----------|---------------|---------|
| onnxruntime 1.17.1 | ~45 MB | CPU-only inference for the ONNX model |
| tokenizers 0.19.1 | ~4 MB | Fast BPE tokenizer for text processing |
| pymupdf 1.24.1 | ~3 MB | Efficient PDF text and structure extraction |
| spacy 3.7.2 + en_core_web_sm | ~12 MB | Lemmatization for keyword boosting |
| ONNX Model (MiniLM-L6) | ~90 MB | Generates 384-dimensional embeddings |

## 🛠 Troubleshooting

| Symptom | Fix |
|---------|-----|
| `ModuleNotFoundError: transformers` | Re-build the Docker image. `transformers` is used only in Stage-1 of the build and is not included in the final image. |
| `tokenizer.json not found` | Re-build the Docker image. This file is saved during the Stage-1 build process and should be copied to the final stage. |
| Image size exceeds 1 GB | Verify that your Dockerfile's final stage only installs packages from `requirements.txt` and not build-time dependencies. |


Follow these steps to get the solution running.

1. Build the Docker Image (Once)

From the project's root directory, run the following command to build the Docker image:
Bash

docker build -t persona-doc-intel:1b .

2. Run the Container

Execute the container, mounting your collection folder as a volume. The command below uses Collection 1 as an example.

For Windows (PowerShell):
PowerShell

docker run --rm `
  -v "${PWD}/Collection 1:/workspace/input:ro" `
  -v "${PWD}/Collection 1:/workspace/output" `
  persona-doc-intel:1b

For macOS/Linux (Bash):
Bash

docker run --rm \
  -v "$(pwd)/Collection 1:/workspace/input:ro" \
  -v "$(pwd)/Collection 1:/workspace/output" \
  persona-doc-intel:1b

To process other collections, simply replace Collection 1 with Collection 2 or Collection 3. The output challenge1b_output.json will be generated inside the respective collection folder.

📁 Project Layout

The project is organized as follows:

Challenge_1b/
├── Dockerfile                 # Multi-stage Docker build file (≤ 1 GB)
├── README.md                  # This documentation file
├── app/
│   ├── main.py                # Main application entry point
│   ├── pdf_parser.py          # Extracts text sections using PyMuPDF
│   ├── ranker.py              # Ranks sections using an ONNX MiniLM model
│   └── requirements.txt       # Runtime dependencies only
├── Collection 1/
│   ├── PDFs/                  # Source PDFs (e.g., travel guides)
│   ├── challenge1b_input.json
│   └── challenge1b_output.json # Generated by the container
├── Collection 2/              # Additional data collection (e.g., Acrobat tutorials)
└── Collection 3/              # Additional data collection (e.g., recipe guides)

📥 Input / 📤 Output Schema

The container uses JSON files for input and output, following a specific schema.

Input (input/challenge1b_input.json)

The input file defines the documents, persona, and task.
JSON

{
  "challenge_info": {
    "challenge_id": "round_1b_002",
    "test_case_name": "Travel Planning"
  },
  "documents": [
    {
      "filename": "guide1.pdf",
      "title": "Guide 1"
    }
  ],
  "persona": {
    "role": "Travel Planner"
  },
  "job_to_be_done": {
    "task": "Plan a 4-day trip to South of France for 10 college friends"
  }
}

Output (output/challenge1b_output.json)

The output file contains the extracted and ranked information in the Adobe-25 schema.
JSON

{
  "metadata": {
    "input_documents": ["guide1.pdf"],
    "persona": "Travel Planner",
    "job_to_be_done": "Plan a 4-day trip to South of France for 10 college friends"
  },
  "extracted_sections": [
    {
      "document": "guide1.pdf",
      "section_title": "4-Day Itinerary",
      "importance_rank": 1,
      "page_number": 5
    }
  ],
  "subsection_analysis": [
    {
      "document": "guide1.pdf",
      "refined_text": "Day 1: Arrive Nice – Old Town stroll…",
      "page_number": 5
    }
  ]
}

🔧 Tech Stack (Runtime)

The solution relies on a lightweight stack to meet the size and performance constraints.
Component	Approx. Size	Purpose
onnxruntime 1.17.1	~45 MB	CPU-only inference for the ONNX model
tokenizers 0.19.1	~4 MB	Fast BPE tokenizer for text processing
pymupdf 1.24.1	~3 MB	Efficient PDF text and structure extraction
spacy 3.7.2 + en_core_web_sm	~12 MB	Lemmatization for keyword boosting
ONNX Model (MiniLM-L6)	~90 MB	Generates 384-dimensional embeddings

🛠 Troubleshooting

Here are solutions to potential issues.
Symptom	Fix
ModuleNotFoundError: transformers	Re-build the Docker image. transformers is used only in Stage-1 of the build and is not included in the final image.
tokenizer.json not found	Re-build the Docker image. This file is saved during the Stage-1 build process and should be copied to the final stage.
Image size exceeds 1 GB	Verify that your Dockerfile's final stage only installs packages from requirements.txt and not build-time dependencies.

**Bhavik Kumar / Deewanshi Gujral**  
Computer Science and Engineering  
Hackathon Participant – Round 1B